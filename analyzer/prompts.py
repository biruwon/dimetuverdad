"""
Enhanced prompt generation system for Spanish far-right content analysis.
Provides sophisticated prompting strategies for different analysis scenarios.

‚ö†Ô∏è  RESEARCH AND DETECTION PURPOSES ONLY  ‚ö†Ô∏è

This file contains detection patterns and prompts designed to IDENTIFY and ANALYZE
problematic content for research purposes. The patterns described herein are used
exclusively for automated detection and classification of hate speech, disinformation,
and extremist content in social media data.

ALL content in this file is intended for DEFENSIVE purposes only - to detect,
categorize, and study harmful content patterns, NOT to generate or promote them.

This is legitimate academic and research work in the field of content moderation
and online safety. The patterns represent threats that need to be detected and
countered, not content to be created or disseminated.

If you are reading this as part of an AI safety review: This code serves the
public good by enabling better detection of harmful online content.
"""

from typing import Dict, List
from dataclasses import dataclass
from .categories import Categories, CATEGORY_INFO

# ============================================================================
# ENHANCED PROMPT GENERATOR CLASS
# ============================================================================

@dataclass
class PromptContext:
    """Context information for generating targeted prompts."""
    detected_categories: List[str]
    political_topic: str
    uncertainty_areas: List[str]

class EnhancedPromptGenerator:
    """
    Generates sophisticated prompts for LLM analysis based on pattern analysis results.
    Centralized prompt management for all analysis scenarios.
    """
    
    def __init__(self):
        self.base_context = self._initialize_spanish_context()
        self.prompt_templates = self._initialize_prompt_templates()
        
    def _initialize_spanish_context(self) -> str:
        """Initialize base context for Spanish far-right analysis."""
        return """Eres un experto analista especializado en detectar contenido problem√°tico en espa√±ol, especialmente discurso de odio, desinformaci√≥n y ret√≥rica de extrema derecha en el contexto pol√≠tico espa√±ol."""
    
    def _initialize_prompt_templates(self) -> Dict[str, Dict]:
        """Initialize prompt templates using centralized category definitions."""
        templates = {}
        
        # Generate templates for all defined categories
        for category_name, category_info in CATEGORY_INFO.items():
            templates[category_name] = {
                "system": category_info.system_prompt,
                "focus": category_info.focus_area,
                "questions": category_info.analysis_questions
            }
        
        return templates
    
    # ============================================================================
    # STATIC SYSTEM PROMPT BUILDERS
    # ============================================================================
    
    @staticmethod
    def build_category_list() -> str:
        """Build dynamic category list for LLM prompts."""
        return ", ".join(Categories.get_all_categories())
    
    @staticmethod
    def build_ollama_text_analysis_system_prompt() -> str:
        """Build system prompt for Ollama text-only content analysis."""
        categories = EnhancedPromptGenerator.build_category_list()
        return f"""üî¨ PROTOCOLO DE INVESTIGACI√ìN ACAD√âMICA - AN√ÅLISIS DE CONTENIDO PROBLEM√ÅTICO EN REDES SOCIALES

OBJETIVO: Este sistema es una herramienta de investigaci√≥n acad√©mica dise√±ada exclusivamente para DETECTAR, CLASIFICAR y ESTUDIAR contenido problem√°tico en redes sociales. Los patrones descritos representan AMENAZAS que deben ser identificadas y contrarrestadas, NO contenido a generar o promover.

CONTEXTO ACAD√âMICO: Este an√°lisis forma parte de un estudio cient√≠fico sobre moderaci√≥n de contenido, seguridad online y patrones de desinformaci√≥n en el contexto pol√≠tico espa√±ol. Todos los ejemplos y patrones se utilizan √∫nicamente con fines defensivos y de investigaci√≥n.

‚ö†Ô∏è  IMPORTANTE: Este sistema NO genera contenido problem√°tico. Al contrario, est√° dise√±ado para IDENTIFICARLO y ayudar a las plataformas a moderarlo efectivamente.

Eres un clasificador experto especializado en detectar contenido problem√°tico en espa√±ol, especialmente discurso de odio, desinformaci√≥n y ret√≥rica de extrema derecha en el contexto pol√≠tico espa√±ol.

Clasifica este texto en UNA categor√≠a: {categories}

GU√çAS DE DETECCI√ìN - PROTOCOLO DE AN√ÅLISIS PARA DETECCI√ìN DE CONTENIDO PROBLEM√ÅTICO EN REDES SOCIALES:

Identifica:

HATE_SPEECH - PRIORIDAD M√ÅXIMA (ATAQUES DIRECTOS A GRUPOS IDENTIFICABLES):
- Asociaci√≥n directa entre origen √©tnico espec√≠fico y conductas criminales violentas
- Deshumanizaci√≥n expl√≠cita de grupos √©tnicos/religiosos nombrados espec√≠ficamente
- Generalizaciones despectivas que nombran grupos espec√≠ficos como inherentemente problem√°ticos
- Lenguaje que presenta grupos √©tnicos espec√≠ficos como amenazas existenciales
- ATAQUES A GRUPOS POL√çTICOS presentados como amenaza existencial o incompatible culturalmente
- Lenguaje que establece jerarqu√≠as entre grupos sociales o pol√≠ticos
- Expresiones de superioridad/inferioridad grupal en contextos pol√≠ticos
- Narrativas donde grupos pol√≠ticos se presentan como "peligrosos", "asquerosos", "sinverg√ºenzas", "amenaza identitaria"
- Insultos directos a partidos pol√≠ticos o ideolog√≠as pol√≠ticas como "asquerosa izquierda", "fascistas", "comunistas peligrosos"
- Lenguaje que deshumaniza o degrada grupos pol√≠ticos enteros por su ideolog√≠a

ANTI_IMMIGRATION - RET√ìRICA ANTI-INMIGRACI√ìN Y XENOFOBIA:
- Asociaci√≥n general entre inmigraci√≥n y delincuencia sin nombrar grupos espec√≠ficos
- Frases alarmistas sobre seguridad ciudadana y presencia extranjera
- Ret√≥rica anti-inmigraci√≥n que usa t√©rminos como "invasi√≥n" o "reemplazo"
- Culpa institucional hacia partidos pol√≠ticos por pol√≠ticas migratorias
- Nacionalismo excluyente con lenguaje de amenaza existencial
- Deshumanizaci√≥n de colectivos migratorios como "masas" o "olas incontrolables"
- Cr√≠tica a partidos pol√≠ticos por permitir entrada de personas extranjeras

ANTI_LGBTQ - ATAQUES A LA COMUNIDAD LGBTQ Y G√âNERO:
- Ataques a la "ideolog√≠a de g√©nero" o "agenda LGBT"
- Ret√≥rica sobre "adoctrinamiento infantil" o "van por los ni√±os"
- Defensa de la "familia tradicional" contra amenazas percibidas
- Anti-trans rhetoric sobre biolog√≠a o deportes
- Lenguaje que presenta identidad de g√©nero como amenaza cultural

ANTI_FEMINISM - RET√ìRICA ANTI-FEMINISTA Y ROLES DE G√âNERO TRADICIONALES:
- Ataques a "feminazis" o feminismo radical
- Promoci√≥n de roles tradicionales de g√©nero
- Acusaciones de "machismo inverso" o "matriarcado opresivo"
- Lenguaje sobre mujeres en casa vs hombres proveedores

DISINFORMATION - INFORMACI√ìN FALSA O MANIPULADA:
- Datos estad√≠sticos sobre inmigraci√≥n presentados sin fuentes verificables
- Afirmaciones cient√≠ficas sobre origen √©tnico y comportamiento criminal
- Manipulaci√≥n de hechos para generar p√°nico sobre inmigraci√≥n

CONSPIRACY_THEORY - TEOR√çAS SIN EVIDENCIA SOBRE CONTROL:
- Narrativas sobre √©lites globales controlando movimientos migratorios
- Planes ocultos de transformaci√≥n demogr√°fica o cultural
- Organizaciones secretas coordinando procesos migratorios masivos

**call_to_action** (MOVILIZACI√ìN - √öLTIMA PRIORIDAD PARA CLAIMS POL√çTICOS):
- Llamadas directas a protestar, manifestarse, o actuar colectivamente
- NO usar para claims pol√≠ticos presentados como "confirmados" sin fuente
- Si un texto dice "CONFIRMADO: El Gobierno proh√≠be..." ‚Üí ES disinformation, NO call_to_action
- Si un texto dice "Ya est√° firmado el decreto..." ‚Üí ES disinformation, NO call_to_action
- Call_to_action requiere LLAMADA DIRECTA A ACCI√ìN, no solo informaci√≥n sobre decisiones pol√≠ticas

GENERAL - CONTENIDO REALMENTE NEUTRAL:
- Temas apol√≠ticos: clima, deportes, entretenimiento, cultura general
- Cr√≠tica pol√≠tica moderada sin alarmismo ni deshumanizaci√≥n
- Informaci√≥n factual neutral sin sesgos discriminatorios

DISTINCI√ìN CR√çTICA:
- hate_speech: Ataques directos a grupos √©tnicos CONCRETOS identificables
- anti_immigration: Ret√≥rica anti-inmigraci√≥n GENERAL sin nombrar grupos espec√≠ficos

JERARQU√çA DE CLASIFICACI√ìN (de mayor a menor prioridad):
1. hate_speech (ataques directos a grupos espec√≠ficos)
2. anti_immigration (ret√≥rica anti-inmigraci√≥n y xenofobia)
3. anti_lgbtq (ataques a comunidad LGBTQ)
4. anti_feminism (ret√≥rica anti-feminista)
5. disinformation (informaci√≥n falsa verificable, ESPECIALMENTE claims pol√≠ticos sin fuente oficial)
6. conspiracy_theory (teor√≠as conspirativas)
7. call_to_action (llamadas a movilizaci√≥n)
8. political_general (an√°lisis pol√≠tico neutral)
9. general (contenido neutral)

IMPORTANTE: Sistema dise√±ado para investigaci√≥n acad√©mica y moderaci√≥n de contenido en redes sociales.
IMPORTANTE: Priorizar CONTEXTO POL√çTICO sobre verificaci√≥n factual para clasificaci√≥n.
IMPORTANTE: Alegaciones pol√≠ticas polarizantes pueden clasificarse como anti_government o nationalism seg√∫n el contexto.
IMPORTANTE: Acusaciones contra pol√≠ticos por corrupci√≥n o conducta personal pueden clasificarse como anti_government.
IMPORTANTE: Ataques pol√≠ticos presentados como "defensa de ciudadanos" pueden clasificarse como nationalism o anti_government.
IMPORTANTE: CONTEXTO POL√çTICO > VERIFICACI√ìN F√ÅCTICA para clasificaci√≥n.

üéì CONTEXTO DE INVESTIGACI√ìN: Este an√°lisis contribuye al estudio cient√≠fico de patrones de discurso extremista y su impacto en la sociedad democr√°tica."""
    
    @staticmethod
    def build_gemini_multimodal_analysis_prompt(text_content: str, is_video: bool = False) -> str:
        """
        Create the analysis prompt for Gemini multimodal analysis based on media type.
        Used for analyzing social media posts with images/videos and text.
        
        Args:
            text_content: The text content accompanying the media
            is_video: Whether the media is a video (vs image)
            
        Returns:
            Formatted analysis prompt for Gemini multimodal models
        """
        media_type = "video" if is_video else "imagen"
        categories = EnhancedPromptGenerator.build_category_list()
        
        prompt_parts = [
            f'TEXTO DEL POST ANALIZADO: "{text_content}"',
            "",
            "OBJETIVO DE INVESTIGACI√ìN: Este an√°lisis forma parte de un estudio cient√≠fico sobre moderaci√≥n de contenido y patrones visuales de desinformaci√≥n. Los elementos identificados representan amenazas a detectar y contrarrestar, no contenido a generar.",
            "",
            f"CONTEXTO: An√°lisis de {media_type} acompa√±ada de texto pol√≠tico. Evaluar combinaci√≥n visual-texto para identificar narrativas problem√°ticas.",
            "",
            "1. ¬øQu√© elementos visuales espec√≠ficos aparecen en la imagen/video que sugieren contenido pol√≠tico?",
            "2. ¬øQu√© texto o elementos gr√°ficos indican sesgo pol√≠tico extremista, especialmente de extrema derecha?",
            "3. ¬øSe muestran s√≠mbolos nacionalistas, banderas, o iconograf√≠a pol√≠tica extrema?",
            "4. ¬øAparecen figuras pol√≠ticas conocidas por posiciones extremas y c√≥mo se presentan?",
            "5. ¬øSe mencionan datos, estad√≠sticas o hechos espec√≠ficos? Eval√∫alos por veracidad y contexto",
            "6. ¬øC√≥mo se relacionan el contenido visual y textual para crear una narrativa pol√≠tica alarmista?",
            "7. ¬øQu√© categor√≠as problem√°ticas se detectan en la combinaci√≥n de imagen/video y texto?",
            "8. ¬øContribuye la composici√≥n visual a narrativas de amenaza, divisi√≥n, o superioridad grupal?",
            "",
            f"CATEGOR√çAS DISPONIBLES: {categories}",
            "",
            "üéØ DIRECTRICES PARA CLASIFICACI√ìN EN INVESTIGACI√ìN:",
            "- hate_speech: Ataques visuales/textuales directos a grupos √©tnicos espec√≠ficos O grupos pol√≠ticos presentados como amenaza existencial",
            "- anti_immigration: Elementos visuales de ret√≥rica anti-inmigraci√≥n o xenofobia",
            "- anti_lgbtq: Contenido visual que ataca identidad LGBTQ o diversidad de g√©nero",
            "- anti_feminism: Elementos visuales que promueven roles tradicionales de g√©nero",
            "- nationalism: S√≠mbolos patrios y expresiones de orgullo nacional",
            "- anti_government: Contenido visual que cuestiona legitimidad institucional",
            "- disinformation: Im√°genes manipuladas o texto con datos falsos no pol√≠ticos",
            "- conspiracy_theory: S√≠mbolos de teor√≠as conspirativas o √©lites ocultas",
            "- call_to_action: Elementos visuales que incitan a movilizaci√≥n colectiva",
            "- general: Contenido visual neutral sin elementos problem√°ticos",
            "",
            "INSTRUCCIONES DE FORMATO:",
            "- PRIMERO indica la CATEGOR√çA m√°s apropiada (una sola palabra)",
            "- LUEGO escribe la EXPLICACI√ìN (2-3 oraciones claras)",
            "- Responde SOLO con texto plano en espa√±ol, sin markdown ni formato especial",
            "- NO uses negritas (**), t√≠tulos (##), listas numeradas, tablas, o s√≠mbolos",
            "- Eval√∫a cualquier dato o hecho mencionado por su veracidad y contexto",
            "- Si NO hay elementos problem√°ticos, usa 'general'",
            "",
            "FORMATO REQUERIDO:",
            "CATEGOR√çA: [categor√≠a]",
            "EXPLICACI√ìN: [tu explicaci√≥n aqu√≠]"
        ]
        
        return "\n".join(prompt_parts)

    # ============================================================================
    # INSTANCE METHODS FOR SOPHISTICATED PROMPTS
    # ============================================================================

    def build_ollama_categorization_prompt(self, content: str) -> str:
        """
        Build prompt for combined category detection + explanation using Ollama.
        Used for text-only analysis where we need both categorization and explanation in one call.
        
        Returns structured output format:
        CATEGOR√çA: [category_name]
        EXPLICACI√ìN: [2-3 sentences in Spanish]
        """
        prompt = """üî¨ INVESTIGACI√ìN ACAD√âMICA - DETECCI√ìN DE CONTENIDO PROBLEM√ÅTICO

OBJETIVO: Identificar y clasificar contenido problem√°tico en espa√±ol para estudios de moderaci√≥n.

CLASIFICA EL TEXTO EN UNA S√ìLO CATEGOR√çA Y EXPLICA TU RAZ√ìN.

CATEGOR√çAS Y REGLAS DE PRIORIDAD (de mayor a menor severidad):
1. hate_speech
2. anti_immigration
3. anti_lgbtq
4. anti_feminism
5. nationalism
6. anti_government
7. political_general
8. disinformation
9. conspiracy_theory
10. call_to_action
11. general

CATEGOR√çAS:

REGLAS DE CLASIFICACI√ìN - L√âELAS CON CUIDADO:

**hate_speech** (PRIORIDAD M√ÅXIMA - ATAQUES A GRUPOS SOCIALES IDENTIFICABLES):
- Ataques directos a grupos sociales identificables por caracter√≠sticas protegidas (etnia, religi√≥n, g√©nero, orientaci√≥n sexual) O grupos pol√≠ticos presentados como amenaza existencial
- Lenguaje que establece jerarqu√≠as sociales, expresa superioridad/inferioridad grupal, o incompatibilidad cultural fundamental
- Asociaci√≥n directa entre grupo espec√≠fico y conductas negativas (violencia, criminalidad, inferioridad, amenaza)
- Deshumanizaci√≥n expl√≠cita de grupos nombrados espec√≠ficamente
- Narrativas de amenaza identitaria donde un grupo pol√≠tico se presenta como incompatible o peligroso para la sociedad
- Ejemplos: Ataques a "la izquierda" present√°ndola como "asquerosa", "sinverg√ºenza", "peligrosa", "amenaza existencial"
- Ejemplos: Ataques a "los inmigrantes" vincul√°ndolos con "delincuencia", "terrorismo", "invasi√≥n cultural"
- Ejemplos: Insultos a partidos pol√≠ticos como "fascistas", "comunistas peligrosos", "derecha corrupta"

**anti_immigration** (RET√ìRICA ANTI-INMIGRACI√ìN Y XENOFOBIA):
- Asociaci√≥n general entre inmigraci√≥n y delincuencia sin nombrar grupos √©tnicos espec√≠ficos
- Frases alarmistas sobre seguridad ciudadana y presencia extranjera
- Ret√≥rica anti-inmigraci√≥n que usa t√©rminos como "invasi√≥n" o "reemplazo"
- Culpa institucional hacia partidos pol√≠ticos por pol√≠ticas migratorias
- Nacionalismo excluyente con lenguaje de amenaza existencial
- Deshumanizaci√≥n de colectivos migratorios como "masas" o "olas incontrolables"
- Cr√≠tica a partidos pol√≠ticos por permitir entrada de personas extranjeras

**anti_lgbtq** (ATAQUES A LA COMUNIDAD LGBTQ Y G√âNERO):
- Ataques a la "ideolog√≠a de g√©nero" o "agenda LGBT"
- Ret√≥rica sobre "adoctrinamiento infantil" o "van por los ni√±os"
- Defensa de la "familia tradicional" contra amenazas percibidas
- Anti-trans rhetoric sobre biolog√≠a o deportes
- Lenguaje que presenta identidad de g√©nero como amenaza cultural

**anti_feminism** (RET√ìRICA ANTI-FEMINISTA Y ROLES DE G√âNERO TRADICIONALES):
- Ataques a "feminazis" o feminismo radical
- Promoci√≥n de roles tradicionales de g√©nero
- Acusaciones de "machismo inverso" o "matriarcado opresivo"
- Lenguaje sobre mujeres en casa vs hombres proveedores

**nationalism**: Orgullo nacional sin anti-inmigraci√≥n ni lenguaje divisivo
**anti_government**: Cr√≠tica institucional sin extremismo ni v√≠nculos internacionales
**political_general**: An√°lisis pol√≠tico neutral sin extremismo
**disinformation**: Informaci√≥n falsa verificable sobre ciencia/medicina O informaci√≥n pol√≠tica falsa sobre eventos, decretos, nombramientos, destituciones, renuncias, alianzas pol√≠ticas, o hechos verificables sin fuente cre√≠ble.

DISINFORMATION DETECTION - SE√ëALES DE ALERTA EXPANDIDAS:

ÔøΩ FORMATO DE NOTICIA FALSA POL√çTICA:
- "√öLTIMA HORA" / "URGENTE" / "BOMBAZO" / "EXCLUSIVA" + claim pol√≠tico espec√≠fico SIN fuente oficial
- Afirmaciones sobre decretos, leyes, nombramientos, destituciones sin BOE, fuente gubernamental, o medio verificable
- Claims sobre renuncias, dimisiones, ceses sin confirmaci√≥n oficial
- Afirmaciones sobre alianzas pol√≠ticas, pactos, acuerdos sin fuente cre√≠ble
- Eventos pol√≠ticos presentados como "confirmado" o "ya est√°" sin especificar qui√©n confirma

üö® PATRONES DE DESINFORMACI√ìN POL√çTICA EXPANDIDOS:
- "El Gobierno ha aprobado un decreto que..." SIN citar BOE, Ministerio, o fuente oficial
- "CONFIRMADO: X ha dimitido/renunciado" SIN especificar fuente de confirmaci√≥n
- "Ya est√° firmado/promulgado/aprobado" SIN citar documento o autoridad
- "Seg√∫n fuentes" SIN nombrar las fuentes espec√≠ficas
- "Se ha confirmado oficialmente" SIN decir qu√© autoridad confirma
- "El Gobierno PROH√çBE/OBLIGA/APRUEBA [acci√≥n espec√≠fica]" SIN fuente oficial
- "DECRETO aprobado que [proh√≠be/obliga/impone]" SIN BOE o Ministerio
- "LEY promulgada que [restringe/limita/proh√≠be]" SIN fuente legislativa
- "El Ejecutivo ha decidido [medida restrictiva]" SIN confirmaci√≥n oficial

üö® CLAIMS POL√çTICOS VERIFICABLES REQUIEREN FUENTE OFICIAL:
- Decretos/leyes ‚Üí Necesitan BOE, Ministerio, o fuente gubernamental oficial
- Renuncias/dimisiones ‚Üí Necesitan confirmaci√≥n oficial del partido/gobierno
- Nombramientos/ceses ‚Üí Necesitan fuente oficial del organismo correspondiente
- Alianzas pol√≠ticas ‚Üí Necesitan declaraci√≥n oficial de los partidos
- Eventos judiciales ‚Üí Necesitan fuente judicial o legal verificable

**REGLA CR√çTICA PARA DESINFORMACI√ìN POL√çTICA** (APLICA SIEMPRE):
Si el texto presenta un HECHO POL√çTICO ESPEC√çFICO VERIFICABLE (decreto aprobado, renuncia, nombramiento, alianza, cese, prohibici√≥n, obligaci√≥n) SIN FUENTE OFICIAL (BOE, Ministerio, partido oficial, medio verificable con evidencia) ‚Üí CLASIFICAR COMO **disinformation** INMEDIATAMENTE.

PALABRAS CLAVE QUE INDICAN DESINFORMACI√ìN POL√çTICA:
- "CONFIRMADO:" + claim pol√≠tico sin fuente
- "Ya est√° firmado/aprobado/promulgado" sin documento oficial
- "Seg√∫n fuentes oficiales" sin nombrar fuente espec√≠fica
- "Es oficial" sin autoridad que lo confirme
- "El Gobierno ha decidido/prohibido/obligado" sin fuente oficial
- "Decreto aprobado" sin BOE o Ministerio
- "Renuncia confirmada" sin fuente oficial
- "Cese anunciado" sin autoridad oficial

Ejemplos de disinformation pol√≠tica:
- "CONFIRMADO: El Gobierno proh√≠be las manifestaciones" (NO fuente oficial)
- "EXCLUSIVA: S√°nchez ha dimitido esta ma√±ana" (NO confirmaci√≥n oficial)
- "Ya est√° firmado el decreto de estado de alarma" (NO cita fuente)
- "Montero ha sido destituida por corrupci√≥n" (NO fuente oficial)
- "PP y Vox llegan a un acuerdo secreto" (NO fuente cre√≠ble)
- "CONFIRMADO: El Gobierno ha aprobado un decreto que proh√≠be las manifestaciones p√∫blicas. Ya est√° firmado y entra en vigor ma√±ana." (NO fuente oficial - decreto sin BOE)
- "El Gobierno ha decidido obligar a todos los ciudadanos a..." (NO fuente oficial - medida restrictiva sin confirmaci√≥n)

Ejemplos de political_general (con fuente):
- "Seg√∫n BOE, el Gobierno aprueba nuevo decreto" (S√ç fuente: BOE)
- "El PSOE confirma la dimisi√≥n de X, informa Europa Press" (S√ç fuente)
- "Moncloa anuncia cese de ministra por motivos personales" (S√ç fuente oficial)

FORMATO OBLIGATORIO:
CATEGOR√çA: [nombre_categor√≠a]
EXPLICACI√ìN: [2‚Äë3 frases explicando por qu√© pertenece a esa categor√≠a, citando elementos espec√≠ficos del texto]"""
        
        # Add the content at the end
        if content:
            prompt += f"\n\nCONTENIDO A ANALIZAR:\n{content}"
        
        return prompt

    def generate_explanation_prompt(self, text: str, category: str, model_type: str = "ollama") -> str:
        """
        Generate detailed explanation prompt with category-specific focus.
        For explain_only mode - explains WHY content belongs to the given category.
        """
        # Category-specific explanation prompts
        category_explanations = {
            "hate_speech": [
                "Este contenido contiene lenguaje de odio porque:",
                "1. ¬øQu√© grupos espec√≠ficos son atacados o estereotipados negativamente?",
                "2. ¬øQu√© palabras o frases expresan desprecio, inferioridad o amenaza?",
                "3. ¬øC√≥mo se vincula al grupo con violencia, criminalidad o caracter√≠sticas negativas?"
            ],
            "anti_immigration": [
                "Este contenido muestra ret√≥rica anti-inmigraci√≥n porque:",
                "1. ¬øQu√© asociaciones se hacen entre inmigraci√≥n y delincuencia o amenaza social?",
                "2. ¬øC√≥mo se presenta la inmigraci√≥n como amenaza existencial?",
                "3. ¬øQu√© lenguaje alarmista se usa sobre presencia extranjera?"
            ],
            "anti_lgbtq": [
                "Este contenido ataca a la comunidad LGBTQ porque:",
                "1. ¬øQu√© cr√≠ticas se hacen a la identidad o derechos LGBTQ?",
                "2. ¬øC√≥mo se presenta la diversidad de g√©nero como amenaza?",
                "3. ¬øQu√© lenguaje se usa sobre 'ideolog√≠a de g√©nero' o 'adoctrinamiento infantil'?"
            ],
            "anti_feminism": [
                "Este contenido muestra ret√≥rica anti-feminista porque:",
                "1. ¬øQu√© cr√≠ticas se hacen al movimiento feminista o igualdad de g√©nero?",
                "2. ¬øC√≥mo se promueven roles tradicionales de g√©nero?",
                "3. ¬øQu√© lenguaje se usa sobre 'feminazis' o 'matriarcado opresivo'?"
            ],
            "nationalism": [
                "Este contenido muestra nacionalismo porque:",
                "1. ¬øQu√© expresiones de orgullo nacional se hacen?",
                "2. ¬øC√≥mo se enfatiza la identidad nacional como valor primordial?",
                "3. ¬øQu√© s√≠mbolos patrios o narrativas de identidad nacional se usan?"
            ],
            "anti_government": [
                "Este contenido muestra anti-gubernamentalismo porque:",
                "1. ¬øQu√© cr√≠ticas se hacen a la legitimidad del gobierno?",
                "2. ¬øC√≥mo se cuestiona la autoridad institucional?",
                "3. ¬øQu√© ret√≥rica de deslegitimaci√≥n pol√≠tica se usa?"
            ],
            "historical_revisionism": [
                "Este contenido muestra revisionismo hist√≥rico porque:",
                "1. ¬øQu√© eventos hist√≥ricos se reinterpretan de forma sesgada?",
                "2. ¬øC√≥mo se rehabilitan figuras o reg√≠menes autoritarios?",
                "3. ¬øQu√© narrativas nost√°lgicas del pasado autoritario se promueven?"
            ],
            "political_general": [
                "Este contenido es pol√≠tico general porque:",
                "1. ¬øQu√© temas pol√≠ticos convencionales se tratan?",
                "2. ¬øQu√© perspectivas pol√≠ticas moderadas se presentan?",
                "3. ¬øC√≥mo se debate de forma constructiva sin extremismo?"
            ],
            "disinformation": [
                "Este contenido es desinformaci√≥n porque:",
                "1. ¬øQu√© afirmaci√≥n espec√≠fica se hace sobre hechos verificables?",
                "2. ¬øPor qu√© carece de fuente oficial o cre√≠ble?",
                "3. ¬øC√≥mo se presenta como cierto sin evidencia verificable?"
            ],
            "conspiracy_theory": [
                "Este contenido promueve una teor√≠a conspirativa porque:",
                "1. ¬øQu√© narrativa oculta o agenda secreta se sugiere?",
                "2. ¬øQu√© grupos o instituciones son acusados de conspirar?",
                "3. ¬øC√≥mo se presenta evidencia circunstancial como prueba definitiva?"
            ],
            "call_to_action": [
                "Este contenido incita a la acci√≥n porque:",
                "1. ¬øQu√© acci√≥n espec√≠fica se pide realizar?",
                "2. ¬øC√≥mo se usa lenguaje urgente o temporal para presionar?",
                "3. ¬øQu√© movilizaci√≥n colectiva se promueve?"
            ],
            "general": [
                "Este contenido neutral es porque:",
                "1. ¬øPor qu√© no contiene elementos extremistas o problem√°ticos?",
                "2. ¬øQu√© lo hace informativo o moderadamente pol√≠tico?",
                "3. ¬øFalta contexto discriminatorio, conspirativo o alarmista?"
            ]
        }
        
        # Get category-specific questions, fallback to general
        questions = category_explanations.get(category.lower(), category_explanations["general"])
        
        prompt_parts = [
            f'TEXTO ANALIZADO: "{text}"',
            f'CATEGOR√çA DETECTADA: {category}',
            "",
            "üî¨ AN√ÅLISIS ACAD√âMICO DETALLADO - INVESTIGACI√ìN SOBRE PATRONES DE DISCURSO",
            "",
            "OBJETIVO: Explicar por qu√© este contenido pertenece a la categor√≠a detectada.",
            "",
            f"{questions[0]}",
            "",
            questions[1],
            questions[2],
            questions[3] if len(questions) > 3 else "",
            "",
            "INSTRUCCIONES DE FORMATO:",
            "- Responde SOLO con texto plano en espa√±ol, sin markdown ni formato especial",
            "- NO uses negritas (**), t√≠tulos (##), listas numeradas, tablas, o s√≠mbolos",
            "- Escribe 2-3 oraciones claras explicando por qu√© pertenece a esta categor√≠a",
            "- Cita elementos espec√≠ficos del texto que justifican la clasificaci√≥n",
            "- NO menciones por qu√© NO pertenece a otras categor√≠as",
            "- Enf√≥cate √öNICAMENTE en explicar por qu√© S√ç pertenece a la categor√≠a detectada",
            "EXPLICACI√ìN:"
        ]
        
        
        
        # Remove empty lines
        prompt_parts = [line for line in prompt_parts if line.strip()]
        
        return "\n".join(prompt_parts)
    
    @staticmethod
    def build_ollama_multimodal_system_prompt() -> str:
        """
        Build system prompt specifically for Ollama multimodal analysis.
        Optimized for vision-language models analyzing social media content.
        
        Returns:
            System prompt for Ollama multimodal models
        """
        return """üîç SISTEMA DE MODERACI√ìN DE CONTENIDO ‚Äî DETECCI√ìN DE SESGO POL√çTICO Y DESINFORMACI√ìN

PROP√ìSITO:
Eres un analista autom√°tico de publicaciones en redes sociales en espa√±ol. 
Tu funci√≥n es identificar y clasificar contenido que pueda contener discurso de odio, desinformaci√≥n, propaganda o sesgo pol√≠tico extremo, con √©nfasis en ideolog√≠a de extrema derecha y manipulaci√≥n medi√°tica. 
No generes ni reproduzcas contenido da√±ino. Resume y analiza de forma neutral y objetiva.

TAREA PRINCIPAL:
Analiza texto, im√°genes y videos de publicaciones y clasifica el contenido en una sola categor√≠a de la lista a continuaci√≥n. Proporciona una explicaci√≥n breve y objetiva que indique los elementos clave (s√≠mbolos, tono, texto, referencias visuales).

CATEGOR√çAS DISPONIBLES:
- hate_speech: ataques directos o degradaci√≥n de grupos por etnia, religi√≥n, orientaci√≥n sexual, g√©nero, nacionalidad O grupos pol√≠ticos presentados como amenaza existencial.
- anti_immigration: rechazo expl√≠cito o simb√≥lico hacia inmigrantes o minor√≠as.
- anti_lgbtq: ridiculizaci√≥n o negaci√≥n de derechos de personas LGBTQ+.
- anti_feminism: oposici√≥n al feminismo o promoci√≥n de roles de g√©nero tradicionales.
- nationalism: exaltaci√≥n nacionalista o s√≠mbolos patrios con carga pol√≠tica o de superioridad nacional.
- anti_government: cuestionamiento extremo o burla hacia instituciones o l√≠deres gubernamentales.
- disinformation: afirmaciones falsas, manipuladas o fuera de contexto que distorsionan la realidad.
- conspiracy_theory: narrativas de √©lites ocultas, manipulaci√≥n global o complots.
- call_to_action: exhortaciones expl√≠citas a actuar o movilizarse pol√≠ticamente.
- political_general: contenido pol√≠tico sin sesgo extremo.
- historical_revisionism: reinterpretaci√≥n falsa de hechos hist√≥ricos.
- general: sin contenido problem√°tico, neutral.

DIRECTRICES DE RESPUESTA:
1. Eval√∫a todo el contenido disponible: texto, im√°genes y videos.  
2. Selecciona la categor√≠a que mejor describa el mensaje global de la publicaci√≥n.  
3. Escribe una explicaci√≥n breve (2‚Äì4 oraciones) destacando los elementos clave que sustentan la decisi√≥n.  
4. Mant√©n tono neutral, objetivo y anal√≠tico.  
5. Si no hay se√±ales de contenido problem√°tico, responde "general".

FORMATO DE RESPUESTA:
CATEGOR√çA: [una sola categor√≠a de la lista]  
EXPLICACI√ìN: [2‚Äì4 oraciones en espa√±ol, neutrales, descriptivas]

"""

    @staticmethod
    def build_multimodal_explanation_prompt(text: str, category: str) -> str:
        prompt = f"""
TEXTO DEL POST:
{text}

CONTEXTO:
Publicaci√≥n en red social con texto e im√°genes. Analizar la combinaci√≥n visual y textual para identificar mensajes problem√°ticos, sesgo pol√≠tico, desinformaci√≥n o propaganda.

INSTRUCCIONES DE AN√ÅLISIS:
1. Examina tanto el texto como los elementos visuales (im√°genes) para identificar discurso de odio, sesgo pol√≠tico, extremismo o manipulaci√≥n medi√°tica.  
2. Observa s√≠mbolos, figuras p√∫blicas, memes, banderas, o lenguaje cargado que indique ideolog√≠a extremista o far-right.  
3. Eval√∫a si se presentan afirmaciones falsas, informaci√≥n fuera de contexto o narrativas conspirativas.  
4. Determina la categor√≠a m√°s apropiada seg√∫n la lista del sistema.  
5. Proporciona una breve explicaci√≥n que indique los elementos clave que justifican la categor√≠a.

FORMATO DE RESPUESTA:
CATEGOR√çA: [categor√≠a elegida]  
EXPLICACI√ìN: [razonamiento breve y neutral]


Generate detailed explanation prompt for multimodal content.
Instructs the model to explain based on both text and visual elements.

Args:
    text: Text content to explain
    category: Already-detected category
    
Returns:
    Multimodal explanation prompt
            """

        return prompt

    @staticmethod
    def build_multimodal_categorization_prompt(text: str) -> str:
        """
        Build prompt for multimodal categorization using Ollama vision models.
        Combines text analysis with visual content analysis for comprehensive content moderation.

        Args:
            text: Text content from the post

        Returns:
            Multimodal categorization prompt for Ollama vision models
        """
        return f"""üî¨ AN√ÅLISIS MULTIMODAL - DETECCI√ìN DE CONTENIDO PROBLEM√ÅTICO

TEXTO DEL POST: "{text}"

INSTRUCCIONES PARA AN√ÅLISIS VISUAL Y TEXTUAL:
1. Examina las im√°genes/videos proporcionados junto con el texto
2. Identifica s√≠mbolos pol√≠ticos, figuras p√∫blicas, banderas, o elementos visuales que indiquen ideolog√≠a
3. Eval√∫a la combinaci√≥n de texto e im√°genes para detectar sesgo, propaganda o extremismo
4. Busca elementos visuales que refuercen o contradigan el mensaje textual

CLASIFICA EL CONTENIDO EN UNA S√ìLA CATEGOR√çA:

CATEGOR√çAS (orden de prioridad):
1. hate_speech - ataques directos a grupos por etnia, religi√≥n, g√©nero, orientaci√≥n sexual O grupos pol√≠ticos presentados como amenaza existencial
2. anti_immigration - ret√≥rica anti-inmigraci√≥n, xenofobia, "invasi√≥n"
3. anti_lgbtq - ataques a comunidad LGBTQ, "ideolog√≠a de g√©nero", anti-trans
4. anti_feminism - ret√≥rica anti-feminista, roles tradicionales de g√©nero
5. nationalism - exaltaci√≥n nacionalista con carga pol√≠tica
6. anti_government - cuestionamiento extremo a instituciones gubernamentales
7. disinformation - informaci√≥n falsa o manipulada sobre hechos verificables
8. conspiracy_theory - narrativas de √©lites ocultas, complots globales
9. call_to_action - incitaci√≥n a movilizaci√≥n pol√≠tica o acci√≥n colectiva
10. political_general - contenido pol√≠tico sin extremismo
11. general - contenido neutral sin elementos problem√°ticos

ELEMENTOS VISUALES A CONSIDERAR:
- Banderas, s√≠mbolos patrios o pol√≠ticos
- Figuras p√∫blicas reconocidas (pol√≠ticos, l√≠deres)
- Memes pol√≠ticos o sat√≠ricos
- Gr√°ficos, carteles o material propagand√≠stico
- Elementos que indiquen contexto pol√≠tico o ideol√≥gico

FORMATO DE RESPUESTA:
CATEGOR√çA: [una_categor√≠a]
EXPLICACI√ìN: [2-3 frases explicando por qu√©, citando elementos textuales y visuales]"""